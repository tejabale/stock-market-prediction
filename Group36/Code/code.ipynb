{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rl5ghzyjVvfj"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "!pip install yfinance   ## installing yfinance python package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkQfwwbJV3cN"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, BatchNormalization\n",
        "from keras.layers import Conv1D, Dense, LSTM, GRU\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import ReLU, Dropout, LayerNormalization\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCj9pPLkWlxn"
      },
      "source": [
        "# Utility functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieeaS1aGWxc-"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "## function to fetch the data as per the start date and column(open, close, volume etc)\n",
        "## returns the data as a numpy array\n",
        "def fetchdata(scrip, start = '2015-10-01', column = 'Close'):\n",
        "  data = yf.download(scrip, start = start)\n",
        "  data = data.reset_index()[column]\n",
        "  print(data)\n",
        "  return np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZW_jUkNsWyWh"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "## function to convert the data into range [0,1] as the values will vary over a large range and values ranges will be different for different stocks\n",
        "def process(data):\n",
        "  data = np.reshape(data, (data.shape[0],1))\n",
        "  scaler = MinMaxScaler(feature_range=(0,1))\n",
        "  df = scaler.fit_transform(data)\n",
        "  return df, scaler   ## returning scaler as well because it will be usefull while converting the values back again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82Hy2OSsW00n"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "## function to convert the scaled values into normal values for plotting\n",
        "def revconvert(data, scaler):\n",
        "  return scaler.inverse_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jvUaAz3W22z"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "## converts the data into stepped data which will be useful while training various networks\n",
        "def convert(data, steps):\n",
        "  x, y = [],[]\n",
        "  for start in range(0,len(data)):\n",
        "    end = start + steps\n",
        "    if end > len(data)-1:\n",
        "      break\n",
        "    xl, yl = data[start : end], data[end]\n",
        "    x.append(xl)\n",
        "    y.append(yl)\n",
        "  return np.array(x), np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YZ3eTx8W-7h"
      },
      "source": [
        "# Functions for plotting and summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmCXCeMbXEDI"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def summary(models):\n",
        "  for model in models:\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "275JtjC-XGEw"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def pltmodel(models):\n",
        "  for model in models:\n",
        "    tf.keras.utils.plot_model(model,show_shapes=True,show_layer_names=False, to_file = f\"{model}.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfvaOdQrXIu0"
      },
      "source": [
        "# Functions to compare the results of models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbWwB2HQXTmb"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def comparemodels(models, modelnames, stockscrips, steps):\n",
        "  for stock in stockscrips:\n",
        "    data = fetchdata(stock)\n",
        "    data, scaler = process(data)\n",
        "    xtrain, ytrain = convert(data, steps)\n",
        "    print(f\"****************** For {stock} ********************\")\n",
        "    i = 0\n",
        "    for model in models:\n",
        "      pred = model.predict(xtrain)\n",
        "      loss = np.sum(np.square(pred - ytrain))\n",
        "      print(f\"Model {modelnames[i]} - Loss {loss}\")\n",
        "      i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPV3xP9VXUbR"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def forecast(models, modelnames, scrips, steps, days = 10):\n",
        "  preds = dict()\n",
        "  for scrip in scrips:\n",
        "    dic = dict()\n",
        "    data = fetchdata(scrip, start = '2019-01-01')   ## most recent data suffices as we'd be using only last steps no of dates for prediction\n",
        "    data, scaler = process(data)\n",
        "    xtrain, ytrain = convert(data, steps)\n",
        "    start = ytrain.shape[0] - steps\n",
        "    for model in modelnames:\n",
        "      a = np.zeros((steps + days,1))\n",
        "      a[0:steps] = ytrain[start:]\n",
        "      dic[model] = a\n",
        "    for i in range(0, days):\n",
        "      for j in range(0, len(models)):\n",
        "        a = dic[modelnames[j]][i:i+steps]\n",
        "        a = np.reshape(a,(1, a.shape[0], a.shape[1]))\n",
        "        pred = models[j].predict(a)\n",
        "        dic[modelnames[j]][i+steps] = pred[0,0]\n",
        "    for model in modelnames:\n",
        "      dic[model] = scaler.inverse_transform(dic[model][steps:])\n",
        "      #dic[model] = dic[model][steps:]\n",
        "    preds[scrip] = dic\n",
        "  return preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up27tbfGXW2L"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def plotresultsforstocks(models, modelnames, stockscrips, steps):\n",
        "  for stock in stockscrips:\n",
        "    data = fetchdata(stock)\n",
        "    data, scaler = process(data)\n",
        "    xtrain, ytrain = convert(data, steps)\n",
        "    print(f\"****************** For {stock} ********************\")\n",
        "    i = 0\n",
        "    for model in models:\n",
        "      pred = model.predict(xtrain)\n",
        "      plt.plot(scaler.inverse_transform(ytrain))\n",
        "      plt.plot(scaler.inverse_transform(pred))\n",
        "      plt.title(f\"Model {modelnames[i]}\")\n",
        "      plt.show()\n",
        "      i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqgsMxZkXY_R"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def plotresults(models, xtrain, ytrain, scaler, modelnames):\n",
        "  i = 0\n",
        "  for model in models:\n",
        "    pred = model.predict(xtrain)\n",
        "    plt.plot(scaler.inverse_transform(ytrain))\n",
        "    plt.plot(scaler.inverse_transform(pred))\n",
        "    plt.title(f\"Model {modelnames[i]}\")\n",
        "    plt.show()\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5CuPASqXbAN"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def plotforecast(modelnames, scrips, preds):    ## should change this by taking inverse transform etc ##\n",
        "  for scrip in scrips:\n",
        "    for model in modelnames:\n",
        "      plt.plot(preds[scrip][model], label = model)\n",
        "    plt.title(f\"Forecast for {scrip}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHABCQJZXjiX"
      },
      "source": [
        "# Functions to return models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSkXsO1OXntH"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def cnnmodel(steps):\n",
        "    model = Sequential([\n",
        "      Conv1D(filters = 32, kernel_size=8, activation = 'relu', input_shape=(steps, 1)),\n",
        "      MaxPooling1D(pool_size=2),\n",
        "      Conv1D(filters = 16, kernel_size = 4, activation = 'relu'),\n",
        "      MaxPooling1D(pool_size=2),\n",
        "      Flatten(),\n",
        "      Dense(16, activation='relu'),\n",
        "      Dense(1),\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_8UwCdaXpeD"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def lstmmodel(steps):\n",
        "  model=Sequential([\n",
        "    LSTM(int(steps/2),return_sequences=True,input_shape=(steps,1)),\n",
        "    LSTM(int(steps/6),return_sequences=True),\n",
        "    LSTM(int(steps/16),return_sequences=True),\n",
        "    LSTM(8),\n",
        "    Dense(1),\n",
        "  ])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faI14tp8XrSx"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def grumodel(steps):\n",
        "  model=Sequential([\n",
        "    GRU(int(steps/2),return_sequences=True,input_shape=(steps,1)),\n",
        "    GRU(int(steps/6),return_sequences=True),\n",
        "    GRU(int(steps/16),return_sequences=True),\n",
        "    GRU(8),\n",
        "    Dense(1),\n",
        "  ])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n4cjUP8XyjJ"
      },
      "source": [
        "# Training the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZSNe_O4X2DB"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def train(models, xtrain, ytrain, epochs = 100, batchsize = 32):\n",
        "  for model in models:\n",
        "    print(f\"************ Training for model {model} *************\")\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    model.fit(xtrain, ytrain, epochs = epochs, batch_size = batchsize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPNSDb3kX3lk"
      },
      "source": [
        "# Main code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B485LkO7X6gi",
        "outputId": "cae724ef-92cf-4ff2-87f7-a11596cf9828"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "data = fetchdata('BTC-USD')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "y6s3ZYB2X9At",
        "outputId": "021ddb41-3ead-4e1f-875a-f67a25ad8145"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "plt.plot(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccp8e5dwX_9f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "steps = 200   ## hyperparameter to be tuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhqlZQRqYAm9"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "databtc, scalerbtc = process(data)\n",
        "xtrain, ytrain = convert(databtc, steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNYSnKV4YDEW"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "cnn = cnnmodel(steps)\n",
        "lstm = lstmmodel(steps)\n",
        "gru = grumodel(steps)\n",
        "\n",
        "models = [cnn, lstm, gru]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00fh5DZ1YE0Y"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "modelnames = ['cnn', 'lstm', 'gru']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZa8G4GnYG4K"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "summary(models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ_2SPrxYIho",
        "outputId": "46a66417-4de2-4bf8-b375-a99feaf58d13"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "train(models, xtrain, ytrain, 100, 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "qG50mJNJYK6B",
        "outputId": "cd7297d0-69e9-47b6-ce75-9f05c773f560"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "plotresults(models, xtrain, ytrain, scalerbtc, modelnames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtsKWR5gYM_T",
        "outputId": "9a35a384-c11c-4523-fed8-3c6ddaa867e6"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "scrips = ['AAPL', 'GOOGL', 'TSLA']\n",
        "comparemodels(models, modelnames, scrips, steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CITuqwlSYQDb",
        "outputId": "6d6fcacd-62bf-44ca-bf58-6a67eeca38d9"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "plotresultsforstocks(models, modelnames, scrips, steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qwi5_DpYYT21",
        "outputId": "d8739f10-5af7-4676-b3b5-8c2d35ba2055"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "preds = forecast(models, modelnames, scrips, steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "id": "3sjfkS8gYWJF",
        "outputId": "7883338b-5431-411a-e4b5-5ac88125abff"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "plotforecast(modelnames, scrips, preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8tnY0h4Y1yF"
      },
      "source": [
        "# Helper functions for transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEQ9RQXbY5nF"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "'''\n",
        "Various indicators\n",
        "'''\n",
        "def daily_return(df: pd.DataFrame):\n",
        "    df['Daily_returns'] = df['Close'].pct_change(1).fillna(0)\n",
        "    return df\n",
        "\n",
        "### MOMENTUM INDICATORS ###\n",
        "def roc_indicator(df: pd.DataFrame):\n",
        "    # Computes rate of change (RoC), i.e momentum - percent change\n",
        "    df[\"RoC\"] = df['Close'].diff() / df['Close'][:-1]\n",
        "    return df\n",
        "\n",
        "def williams_r(df: pd.DataFrame, lookback: int):\n",
        "    # Computes Williams %R that measures overbought and oversold levels\n",
        "    wr = np.zeros(len(df))\n",
        "    for t_idx in range(len(df)):\n",
        "        if t_idx + 1 <= lookback:\n",
        "            wr[t_idx] = 0\n",
        "        else:\n",
        "            highest = np.max(df['High'][t_idx-lookback:t_idx].values)\n",
        "            lowest = np.min(df['Low'][t_idx-lookback:t_idx].values)\n",
        "            wr[t_idx] = (highest - df['Close'][t_idx]) / (highest - lowest)\n",
        "    df[\"williams_r\"] = wr\n",
        "    return df\n",
        "\n",
        "### VOLUME INDICATORS ###\n",
        "def money_flow_index(df: pd.DataFrame, period: int):\n",
        "    # Measures buying and selling pressure (if below 20 then buy if above 80 then sell)\n",
        "    typical_price = (df['Close'] + df['High'] + df['Low']) / 3\n",
        "    money_flow = typical_price * df['Volume']\n",
        "    positive_flow, negative_flow = [], []\n",
        "    for i in range(1, len(typical_price)):\n",
        "        if typical_price[i] > typical_price[i-1]:\n",
        "            positive_flow.append(money_flow[i-1])\n",
        "            negative_flow.append(0)\n",
        "        elif typical_price[i] < typical_price[i-1]:\n",
        "            positive_flow.append(0)\n",
        "            negative_flow.append(money_flow[i-1])\n",
        "        else:\n",
        "            positive_flow.append(0)\n",
        "            negative_flow.append(0)\n",
        "\n",
        "    positive_mf = [sum(positive_flow[i + 1 - period:i + 1]) for i in range(period-1, len(positive_flow))]\n",
        "    negative_mf = [sum(negative_flow[i + 1 - period:i + 1]) for i in range(period - 1, len(negative_flow))]\n",
        "    idx = 0\n",
        "    mfi = np.zeros(len(df))\n",
        "    for t_idx in range(len(df)):\n",
        "        if t_idx + 1 <= period:\n",
        "            mfi[t_idx] = 0\n",
        "        else:\n",
        "            mfi[t_idx] = 100 * (positive_mf[idx] / (positive_mf[idx] + negative_mf[idx]))\n",
        "            idx += 1\n",
        "    df[\"MFI\"] = mfi\n",
        "    return df\n",
        "\n",
        "### VOLATILITY INDICATORS ###\n",
        "def ulcer_index(df: pd.DataFrame, lookback: int):\n",
        "    # Measures downside risk in terms of depth and duration of price declines\n",
        "    ui = np.zeros(len(df))\n",
        "    for t_idx in range(len(df)):\n",
        "        if t_idx + 1 <= lookback:\n",
        "            ui[t_idx] = 0\n",
        "        else:\n",
        "            maxprice = np.max(df['Close'][t_idx-lookback:t_idx].values)\n",
        "            percentage_drawdown = [(df['Close'][t_idx-i]-maxprice)/maxprice * 100 for i in reversed(range(lookback))]\n",
        "            ulcer_ind = np.sqrt(np.sum(np.array(percentage_drawdown)**2) / lookback)\n",
        "            ui[t_idx] = ulcer_ind\n",
        "    df['Ulcer_index'] = ui\n",
        "    return df\n",
        "\n",
        "def average_true_range(df: pd.DataFrame, lookback: int):\n",
        "    # Measures market volatility\n",
        "    av_tr_rang = np.zeros(len(df))\n",
        "    for t_idx in range(len(df)):\n",
        "        if t_idx + 1 <= lookback:\n",
        "            av_tr_rang[t_idx] = 0\n",
        "        else:\n",
        "            true_ranges = []\n",
        "            for idx in reversed(range(lookback)):\n",
        "                tr1 = df['High'][t_idx-idx] - df['Low'][t_idx-idx]\n",
        "                tr2 = np.abs(df['High'][t_idx-idx] - df['Close'][t_idx-idx])\n",
        "                tr3 = np.abs(df['Low'][t_idx-idx] - df['Close'][t_idx-idx])\n",
        "                true_ranges.append(np.max([tr1, tr2, tr3]))\n",
        "            atr = sum(true_ranges) / lookback\n",
        "            av_tr_rang[t_idx] = atr\n",
        "    df['ATR'] = av_tr_rang\n",
        "    return df\n",
        "\n",
        "### TREND INDICATORS ###\n",
        "\n",
        "def simple_moving_average(df: pd.DataFrame, windows: list):\n",
        "    for window in windows:\n",
        "        df[f'SMA_{window}'] = df['Close'].rolling(window=window).mean().fillna(0)\n",
        "    return df\n",
        "\n",
        "def exponential_moving_average(df: pd.DataFrame, windows: list):\n",
        "    for window in windows:\n",
        "        df[f'EMA_{window}'] = df['Close'].ewm(span=window, adjust=False).mean().fillna(0)\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_indicators(df: pd.DataFrame):\n",
        "    df = daily_return(df)\n",
        "    df = roc_indicator(df)\n",
        "    df = williams_r(df, 14)\n",
        "    df = money_flow_index(df, 14)\n",
        "    df = ulcer_index(df, 14)\n",
        "    df = average_true_range(df, 14)\n",
        "    df = simple_moving_average(df, [5, 10, 20])\n",
        "    df = exponential_moving_average(df, [20, 50])\n",
        "    return df\n",
        "\n",
        "def preprocess_data(df):\n",
        "    if df.columns[0] == 'Date':\n",
        "        df = df.set_index('Date')\n",
        "\n",
        "    df = get_indicators(df)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGwnlHqvZD-x"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def get_stationary_data(df:pd.DataFrame, columns:list, diff:int):\n",
        "    # Making the data stationary\n",
        "    df_cp = df.copy()\n",
        "    for col in columns:\n",
        "        df_cp[str(col)] = pd.DataFrame(np.log(df_cp[str(col)]).diff().diff(diff))\n",
        "    return df_cp\n",
        "\n",
        "def inverse_stationary_data(old_df:pd.DataFrame, new_df: pd.DataFrame, orig_feature: str,\n",
        "                            new_feature: str, diff: int, do_orig=True):\n",
        "    # Inverse the stationary data transformation\n",
        "\n",
        "    if do_orig:\n",
        "        new_df[orig_feature] += np.log(old_df[orig_feature]).shift(1)\n",
        "        new_df[orig_feature] += np.log(old_df[orig_feature]).diff().shift(diff)\n",
        "        new_df[orig_feature] = np.exp(new_df[orig_feature])\n",
        "    new_df[new_feature] += np.log(old_df[orig_feature]).shift(1)\n",
        "    new_df[new_feature] += np.log(old_df[orig_feature]).diff().shift(diff)\n",
        "    new_df[new_feature] = np.exp(new_df[new_feature])\n",
        "    return new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnkW0kFOZHWc"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "class GetDataset(object):\n",
        "    def __init__(self, df):\n",
        "        super(GetDataset, self).__init__()\n",
        "        self.df = df\n",
        "        self.df[\"Next_day_closing_price\"] = df[\"Close\"].shift(-1).dropna()\n",
        "        if self.df.columns[0] == 'Date':\n",
        "            self.df = self.df.set_index('Date')\n",
        "        self.df[\"Actual\"] = self.df[\"Next_day_closing_price\"]\n",
        "\n",
        "\n",
        "\n",
        "    def get_dataset(self, scale=True, stationary=True, indicators=False):\n",
        "        '''\n",
        "            Input: scale - if to scale the input data\n",
        "        '''\n",
        "        x_df = self.df[[\"Close\", \"Open\", \"High\", \"Low\", \"Volume\"]].dropna()[:-1]\n",
        "        y_df = self.df[\"Next_day_closing_price\"].dropna().fillna(0)\n",
        "\n",
        "        x_processed_df = preprocess_data(x_df).fillna(0)\n",
        "        if stationary:\n",
        "            for col in x_processed_df.columns:\n",
        "                x_processed_df = get_stationary_data(x_processed_df, [col], 12)\n",
        "\n",
        "            y_df = get_stationary_data(self.df, [\"Next_day_closing_price\"], 12)['Next_day_closing_price']\n",
        "            y_df.replace([np.inf, -np.inf, np.nan], 0, inplace=True)\n",
        "        x_processed_df.replace([np.inf, -np.inf], 0, inplace=True)\n",
        "\n",
        "\n",
        "        self.x_data_values = x_processed_df.fillna(0).values[:-1]\n",
        "        self.y_data_values = y_df.values[:-1].reshape(-1, 1)\n",
        "\n",
        "        self.x_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "        self.y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "        if scale:\n",
        "            self.x_data = self.x_scaler.fit_transform(self.x_data_values)\n",
        "            self.y_data = self.y_scaler.fit_transform(self.y_data_values)\n",
        "        else:\n",
        "            self.x_data = self.x_data_values\n",
        "            self.y_data = self.y_data_values\n",
        "\n",
        "\n",
        "    def get_size(self):\n",
        "        '''\n",
        "            Output: returns the length of the dataset\n",
        "        '''\n",
        "        return len(self.x_data)\n",
        "\n",
        "\n",
        "    def split(self, train_split_ratio=0.8, time_period=30):\n",
        "        '''\n",
        "            Input: train_split_ratio - percentage of dataset to be used for\n",
        "                                       the training data (float)\n",
        "                   time_period - time span in days to be predicted (in)\n",
        "\n",
        "            Output: lists of the training and validation data (input values and target values)\n",
        "                    size of the training data\n",
        "        '''\n",
        "\n",
        "        train_data_size = int(np.ceil(self.get_size() * train_split_ratio))\n",
        "        x_train_data = self.x_data[:train_data_size]\n",
        "        y_train_data = self.y_data[:train_data_size]\n",
        "\n",
        "        x_train = [x_train_data[i-time_period:i] for i in range(time_period, len(x_train_data))]\n",
        "        y_train = y_train_data[time_period:]\n",
        "\n",
        "\n",
        "        self.y_train = np.array(y_train)\n",
        "        self.x_train = np.array(x_train)\n",
        "        print(f'Shape of train data: (x, y) = ({np.shape(self.x_train)}, {np.shape(self.y_train)})')\n",
        "\n",
        "        x_test_data = self.x_data[train_data_size - time_period:]\n",
        "        y_test = self.y_data[train_data_size:]\n",
        "        x_test = [x_test_data[i-time_period:i] for i in range(time_period, len(x_test_data))]\n",
        "\n",
        "        self.y_test = np.array(y_test)\n",
        "        self.x_test = np.array(x_test)\n",
        "        print(f'Shape of test data: (x, y) = ({np.shape(self.x_test)}, {np.shape(self.y_test)})')\n",
        "        return [self.x_train, self.y_train], [self.x_test, self.y_test], train_data_size\n",
        "\n",
        "\n",
        "    def get_torchdata(self):\n",
        "        self.x_train_tensor = torch.from_numpy(self.x_train).type(torch.Tensor)\n",
        "        self.x_test_tensor = torch.from_numpy(self.x_test).type(torch.Tensor)\n",
        "\n",
        "        self.y_train_tensor = torch.from_numpy(self.y_train).type(torch.Tensor)\n",
        "        self.y_test_tensor = torch.from_numpy(self.y_test).type(torch.Tensor)\n",
        "\n",
        "        return [self.x_train_tensor, self.y_train_tensor], [self.x_test_tensor, self.y_test_tensor]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwkNHeVLZUOV"
      },
      "source": [
        "# Implementation of a transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIxKNu14ZYJA"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def scaled_dot_product_attention(query, key, value):\n",
        "    '''\n",
        "    Computes the local fields and the attention of the inputs as described in Vaswani et. al.\n",
        "    and then scale it for a total sum of 1\n",
        "\n",
        "    INPUT: query, key, value - input data of size (batch_size, seq_length, num_features)\n",
        "    '''\n",
        "\n",
        "    temp = query.bmm(key.transpose(1, 2))\n",
        "    scale = query.size(-1) ** 0.5\n",
        "    softmax = f.softmax(temp / scale, dim=-1)\n",
        "    attention = softmax.bmm(value)\n",
        "    return attention\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    '''\n",
        "    Computes the multihead head consisting of a feedforward layer for each input value\n",
        "    where the attention for all of these are computed for each head and then concatenated and projected\n",
        "    as described in Vaswani et. al.\n",
        "\n",
        "    INPUT: dimensions of the three matrices (where the key and query matrix has the same dimensions) and the nr of heads\n",
        "    OUTPUT: the projected output of the multihead attention\n",
        "    '''\n",
        "\n",
        "    def __init__(self, num_heads, input_dim, key_dim, value_dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(input_dim, key_dim)\n",
        "        self.key = nn.Linear(input_dim, key_dim)\n",
        "        self.value = nn.Linear(input_dim, value_dim)\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.linear = nn.Linear(num_heads * value_dim, input_dim)\n",
        "\n",
        "    def forward(self, query, key, value):\n",
        "        multiheads_out = [\n",
        "            scaled_dot_product_attention(self.query(query), self.key(key), self.value(value)) for _ in\n",
        "            range(self.num_heads)\n",
        "        ]\n",
        "        out = self.linear(torch.cat(multiheads_out, dim=-1))\n",
        "        return out\n",
        "\n",
        "\n",
        "def positioning_encoding(seq_length, model_dim):\n",
        "    '''\n",
        "    Computes the positional encoding for the current state of the elements in the input sequence as\n",
        "    there is no recurrence or convolution. Using the same encoding with sinusosoidal functions as in Vaswani et. al.\n",
        "    as the motivations of linearly dependency of the relative positions and the ability to extrapolate to sequence lengths\n",
        "    longer than encountered in training holds strong.\n",
        "    Code copied from Frank Odom\n",
        "\n",
        "    INPUT: length of the input sequence and the dimension of the model\n",
        "    OUTPUT: Encoded relative positions of the data points in the input sequence\n",
        "    '''\n",
        "    position = torch.arange(seq_length, dtype=torch.float).reshape(1, -1, 1)\n",
        "    frequencies = 1e-4 ** (2 * (torch.arange(model_dim, dtype=torch.float) // 2) / model_dim).reshape(1, 1, -1)\n",
        "    pos_enc = position * frequencies\n",
        "    pos_enc[:, ::2] = torch.cos(pos_enc[:, ::2])\n",
        "    pos_enc[:, 1::2] = torch.sin(pos_enc[:, 1::2])\n",
        "    return pos_enc\n",
        "\n",
        "\n",
        "def forward(input_dim=512, forward_dim=2048):\n",
        "    '''\n",
        "    Forward class for the feed-forward layer that is following the multihead\n",
        "    attention layers\n",
        "\n",
        "    INPUT: input dimension and the layer size of the forward layer\n",
        "    OUTPUT: feed-forward layer (nn.Module)\n",
        "    '''\n",
        "    forward_layer = nn.Sequential(\n",
        "        nn.Linear(input_dim, forward_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(forward_dim, input_dim)\n",
        "    )\n",
        "    return forward_layer\n",
        "\n",
        "\n",
        "class ResidualConnection(nn.Module):\n",
        "    '''\n",
        "    Class for the residual connections for the encoder and the decoder, used for each multihead attention layer\n",
        "    and for each feed-forward layer\n",
        "\n",
        "    INPUT: type of layer, dimension for the layer normalization and dropout probability factor\n",
        "    OUTPUT: Normalized and processed tensors added to the input tensors\n",
        "    '''\n",
        "\n",
        "    def __init__(self, layer, dimension, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.layer = layer\n",
        "        self.norm = nn.LayerNorm(dimension)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, *X):\n",
        "        return self.norm(X[-1] + self.dropout(self.layer(*X)))\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    '''\n",
        "    The encoder of the transformer model, first computes the relative positions of the inputs, then feeds it into\n",
        "    the multihead attention followed by the feed-forward layer, both with normalized residual connections\n",
        "    '''\n",
        "\n",
        "    def __init__(self, n_layers=6, model_dim=512, num_heads=8, forward_dim=2048, dropout=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_layers = n_layers\n",
        "        key_dim = value_dim = model_dim // num_heads\n",
        "\n",
        "        # Multihead attention layer with normalized residual connections and dropout\n",
        "        self.multihead_attention = ResidualConnection(\n",
        "            MultiHeadAttention(num_heads, model_dim, key_dim, value_dim),\n",
        "            dimension=model_dim,\n",
        "            dropout=dropout\n",
        "        )\n",
        "        # Feed-forward layer with normalized residual connections and dropout\n",
        "        self.feed_forward = ResidualConnection(\n",
        "            forward(model_dim, forward_dim),\n",
        "            dimension=model_dim,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        seq_length, dimension = X.size(1), X.size(2)\n",
        "        out = X\n",
        "        # Computes the positional encodings\n",
        "        out += positioning_encoding(seq_length, dimension)\n",
        "        # Feeds the input to the multihead attention layer followed by the feed-forward\n",
        "        # layer for 'n_layers' many layers\n",
        "        for _ in range(self.n_layers):\n",
        "            att_out = self.multihead_attention(out, out, out)\n",
        "            out = self.feed_forward(att_out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class transformerModel(nn.Module):\n",
        "    def __init__(self, n_layers=6, model_dim=512, output_dim=512,\n",
        "                 num_heads=6, forward_dim=2048, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(n_layers, model_dim, num_heads, forward_dim, dropout)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear = nn.Linear(16, output_dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, X):\n",
        "        enc_out = self.encoder(X)\n",
        "        #flat = self.flatten(enc_out)\n",
        "        out = self.relu(self.linear(enc_out[:, -1, :]))\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhy7r75iZhxT"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "class transf_params:\n",
        "    n_layers = 11\n",
        "    num_heads = 6\n",
        "    model_dim = 16  # nr of features\n",
        "    forward_dim = 128\n",
        "    output_dim = 1\n",
        "    dropout = 0\n",
        "    n_epochs = 100\n",
        "    lr = 0.01\n",
        "    batch_size = 32\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.transf = transformerModel(n_layers=params.n_layers,\n",
        "                                                   num_heads=params.num_heads,\n",
        "                                                   model_dim=params.model_dim,\n",
        "                                                   forward_dim=params.forward_dim,\n",
        "                                                   output_dim=16,\n",
        "                                                   dropout=params.dropout)\n",
        "        self.linear = nn.Linear(16, params.output_dim)\n",
        "    def forward(self, x):\n",
        "        transf_out = self.transf(x)\n",
        "        out = self.linear(transf_out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYg2h_YmZjnY"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "class Classifier(object):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def train(self, train_data, params):\n",
        "        '''\n",
        "            Input: train_data - list of input values (numpy array) and target values\n",
        "                                (numpy array) of training data\n",
        "                   model - model to be trained\n",
        "                   show_progress - if the training process is showed (boolean)\n",
        "\n",
        "        '''\n",
        "        self.x_train, self.y_train = train_data\n",
        "        criterion = torch.nn.MSELoss(reduction='mean')\n",
        "        optimiser = torch.optim.Adam(self.model.parameters(), lr=params.lr)\n",
        "        hist = np.zeros(params.n_epochs)\n",
        "        self.model.train()\n",
        "        for epoch in range(params.n_epochs):\n",
        "            y_train_pred = self.model(self.x_train)\n",
        "            loss = criterion(y_train_pred, self.y_train)\n",
        "            optimiser.zero_grad()\n",
        "            loss.backward()\n",
        "            optimiser.step()\n",
        "            print(f'Epoch: {epoch+1}/{params.n_epochs}\\tMSE loss: {loss.item():.5f}')\n",
        "            hist[epoch] = loss.item()\n",
        "\n",
        "        return hist\n",
        "\n",
        "\n",
        "    def predict(self, test_data, scaler, data_scaled=True):\n",
        "        '''\n",
        "            Input: test_data - list of input values (numpy array) and target values\n",
        "                               (numpy array) of validation data\n",
        "                   scaler - scaler object to inversely scale predictions\n",
        "                   data_scaled - if scaler were used in the preprocessing (boolean)\n",
        "\n",
        "            Output: predictions - numpy array of the predicted values\n",
        "        '''\n",
        "\n",
        "\n",
        "        self.x_test, self.y_test = test_data\n",
        "        self.model.eval()\n",
        "        predictions = self.model(self.x_test).detach().numpy()\n",
        "        if data_scaled:\n",
        "            predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TISTNboQZojI"
      },
      "source": [
        "# Training code for transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaaGFsnWZzCX",
        "outputId": "b9a5b62f-d30d-4e41-cb24-c36004826836"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "scrip = 'BTC-USD'\n",
        "start = '2015-10-01'\n",
        "df = yf.download(scrip, start = start)\n",
        "dataset = GetDataset(df)\n",
        "dataset.get_dataset(scale=False)\n",
        "\n",
        "train_data, test_data, train_data_len = dataset.split(train_split_ratio=1, time_period=30)\n",
        "\n",
        "train_data, test_data = dataset.get_torchdata()\n",
        "x_train, y_train = train_data\n",
        "x_test, y_test = test_data\n",
        "\n",
        "params = transf_params\n",
        "model = TransformerModel(params)\n",
        "\n",
        "clf = Classifier(model)\n",
        "clf.train([x_train, y_train], params=params)\n",
        "y_scaler = dataset.y_scaler\n",
        "# predictions = clf.predict([x_train, y_train], y_scaler, data_scaled=False)\n",
        "# predictions = pd.DataFrame(predictions)\n",
        "\n",
        "# predictions.reset_index(drop=True, inplace=True)\n",
        "# predictions.index = df.index[-len(x_train):]\n",
        "# predictions['Actual'] = y_train\n",
        "# predictions.rename(columns={0: 'Predictions'}, inplace=True)\n",
        "\n",
        "\n",
        "# predictions = inverse_stationary_data(old_df=df, new_df=predictions,\n",
        "#                                       orig_feature='Actual', new_feature='Predictions',\n",
        "#                                       diff=12, do_orig=True)\n",
        "    \n",
        "# print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "nuJ3Kb8WcXQg",
        "outputId": "a8ae6f80-9239-4538-fe90-ad2a8a0eee30"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "preds = clf.predict([x_train, y_train], y_scaler, data_scaled=False)\n",
        "preds = pd.DataFrame(preds)\n",
        "\n",
        "preds.reset_index(drop=True, inplace=True)\n",
        "preds.index = df.index[-len(x_train):]\n",
        "preds['Actual'] = y_train\n",
        "preds.rename(columns={0: 'Predictions'}, inplace=True)\n",
        "\n",
        "\n",
        "preds = inverse_stationary_data(old_df=df, new_df=preds,\n",
        "                                      orig_feature='Actual', new_feature='Predictions',\n",
        "                                      diff=12, do_orig=True)\n",
        "\n",
        "predic = preds['Predictions']\n",
        "act = preds['Actual']\n",
        "plt.plot(predic)\n",
        "plt.plot(act)\n",
        "plt.title(\"Training results for transformers(BTC-USD)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CBNwINOLebs8",
        "outputId": "4b808d7b-ade4-4403-95c5-b1e5e3834147"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mSyntaxError: invalid syntax. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def plotTransformerResults(clf):\n",
        "    for scrip in scrips:\n",
        "        df = yf.download(scrip, start = start)\n",
        "        dataset = GetDataset(df)\n",
        "        dataset.get_dataset(scale=False)\n",
        "\n",
        "        train_data, test_data, train_data_len = dataset.split(train_split_ratio=1, time_period=30)\n",
        "\n",
        "        train_data, test_data = dataset.get_torchdata()\n",
        "        x_train, y_train = train_data\n",
        "\n",
        "        preds = clf.predict([x_train, y_train], y_scaler, data_scaled=False)\n",
        "        preds = pd.DataFrame(preds)\n",
        "\n",
        "        preds.reset_index(drop=True, inplace=True)\n",
        "        preds.index = df.index[-len(x_train):]\n",
        "        preds['Actual'] = y_train\n",
        "        preds.rename(columns={0: 'Predictions'}, inplace=True)\n",
        "\n",
        "\n",
        "        preds = inverse_stationary_data(old_df=df, new_df=preds,\n",
        "                                            orig_feature='Actual', new_feature='Predictions',\n",
        "                                            diff=12, do_orig=True)\n",
        "\n",
        "        predic = preds['Predictions']\n",
        "        act = preds['Actual']\n",
        "        predic = pd.DataFrame(predic)\n",
        "        act = pd.DataFrame(act)\n",
        "        \n",
        "        print(\"Loss for \" + scrip + \"stock\", np.mean((np.array(predic[\"Predictions\"]) - np.array(act[\"Actual\"]))**2))\n",
        "        plt.plot(np.array(predic[\"Predictions\"]))\n",
        "        plt.plot(np.array(act[\"Actual\"]))\n",
        "        plt.title(f\"Results for stock {scrip} using Transformers\")\n",
        "        plt.show()\n",
        "\n",
        "plotTransformerResults(clf)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
